{
    "contents" : "## Begin by loading the required packages\n## If they are not installed in your system then install them from Cran-R \n## using install.packages('package_name')\nlibrary(caret)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(RColorBrewer)\nlibrary(rattle)\nlibrary(e1071)\nlibrary(randomForest)\n\n## Get the data from the URLs in the assignment and set the NA variables to NA\ntrainUrl <- \"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\ntestUrl <- \"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\ntraining <- read.csv(url(trainUrl), na.strings=c(\"NA\",\"#DIV/0!\",\"\"))\ntesting <- read.csv(url(testUrl), na.strings=c(\"NA\",\"#DIV/0!\",\"\"))\n\n## Particion the training data set for 60% training 40% testing\ninTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)\nmyTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]\ndim(myTraining); dim(myTesting)\n## You should have 11,776 cases in training and 7,846 in testing\n\n## Clean the data\n\n## Because the file is so big we will look for variables with\n## Near-zero variances\nmyDataNZV <- nearZeroVar(myTraining, saveMetrics=TRUE)\n\n## Take a look\nmyNZVvars <- names(myTraining) %in% c(\"new_window\", \"kurtosis_roll_belt\", \"kurtosis_picth_belt\",\n                                      \"kurtosis_yaw_belt\", \"skewness_roll_belt\", \"skewness_roll_belt.1\", \"skewness_yaw_belt\",\n                                      \"max_yaw_belt\", \"min_yaw_belt\", \"amplitude_yaw_belt\", \"avg_roll_arm\", \"stddev_roll_arm\",\n                                      \"var_roll_arm\", \"avg_pitch_arm\", \"stddev_pitch_arm\", \"var_pitch_arm\", \"avg_yaw_arm\",\n                                      \"stddev_yaw_arm\", \"var_yaw_arm\", \"kurtosis_roll_arm\", \"kurtosis_picth_arm\",\n                                      \"kurtosis_yaw_arm\", \"skewness_roll_arm\", \"skewness_pitch_arm\", \"skewness_yaw_arm\",\n                                      \"max_roll_arm\", \"min_roll_arm\", \"min_pitch_arm\", \"amplitude_roll_arm\", \"amplitude_pitch_arm\",\n                                      \"kurtosis_roll_dumbbell\", \"kurtosis_picth_dumbbell\", \"kurtosis_yaw_dumbbell\", \"skewness_roll_dumbbell\",\n                                      \"skewness_pitch_dumbbell\", \"skewness_yaw_dumbbell\", \"max_yaw_dumbbell\", \"min_yaw_dumbbell\",\n                                      \"amplitude_yaw_dumbbell\", \"kurtosis_roll_forearm\", \"kurtosis_picth_forearm\", \"kurtosis_yaw_forearm\",\n                                      \"skewness_roll_forearm\", \"skewness_pitch_forearm\", \"skewness_yaw_forearm\", \"max_roll_forearm\",\n                                      \"max_yaw_forearm\", \"min_roll_forearm\", \"min_yaw_forearm\", \"amplitude_roll_forearm\",\n                                      \"amplitude_yaw_forearm\", \"avg_roll_forearm\", \"stddev_roll_forearm\", \"var_roll_forearm\",\n                                      \"avg_pitch_forearm\", \"stddev_pitch_forearm\", \"var_pitch_forearm\", \"avg_yaw_forearm\",\n                                      \"stddev_yaw_forearm\", \"var_yaw_forearm\")\nmyTraining <- myTraining[!myNZVvars]\n\n## To check the new number of observations\ndim(myTraining)\n## You should now have 100 variables for each case where before you had 160\n\n## Eliminate the ID numbers as they will mess up the correlations\nmyTraining <- myTraining[c(-1)]\n\n## Get rid of the variables with too many NAs in the set\ntrainingV3 <- myTraining #creating another subset to iterate in loop\nfor(i in 1:length(myTraining)) { #for every column in the training dataset\n  if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .6 ) { #if n?? NAs > 60% of total observations\n    for(j in 1:length(trainingV3)) {\n      if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) ==1)  { #if the columns are the same:\n        trainingV3 <- trainingV3[ , -j] #Remove that column\n      }   \n    } \n  }\n}\n\n## To check the new N again\ndim(trainingV3)\n## You should have 58 variables now rather than 60\n\n## We're done cleaning the myTraining training set so let's\n## Set it back to the original name and clean up our extra sets:\nmyTraining <- trainingV3\nrm(trainingV3)\n\n## Clean up the other sets using the same procedure\n## On the MyTraining testing set and the actual testing set\nclean1 <- colnames(myTraining)\nclean2 <- colnames(myTraining[, -58]) # already with classe column removed\nmyTesting <- myTesting[clean1]\ntesting <- testing[clean2]\n\n## Check the new N\ndim(myTesting)\ndim(testing)\n\n## Coerce the data to the same type to work with the trees software\nfor (i in 1:length(testing) ) {\n  for(j in 1:length(myTraining)) {\n    if( length( grep(names(myTraining[i]), names(testing)[j]) ) ==1)  {\n      class(testing[j]) <- class(myTraining[i])\n    }      \n  }      \n}\n\n## And to make sure Coertion really worked, simple smart ass technique:\ntesting <- rbind(myTraining[2, -58] , testing) #note row 2 does not mean anything, so remove it\ntesting <- testing[-1,]\n\n## First, use the decision tree algorithm to \n## identify the groupings of teh variables for predictions\nmodFitA1 <- rpart(classe ~ ., data=myTraining, method=\"class\")\n\n## Take a look at the graph\nfancyRpartPlot(modFitA1)\n\n## Now do the predictions on myTesting set\npredictionsA1 <- predict(modFitA1, myTesting, type = \"class\")\n\n## Use confusionMatrix to test the results\nconfusionMatrix(predictionsA1, myTesting$classe)\n## Take a look at your results - overall accuracy should be\n## 0.8663 (95% CI 0.08586 - 0.08738)\n\n## Let's compare to another method: Random Forest groupings\nmodFitB1 <- randomForest(classe ~. , data=myTraining)\npredictionsB1 <- predict(modFitB1, myTesting, type = \"class\")\nconfusionMatrix(predictionsB1, myTesting$classe)\n## Wow! Much better - overall accuracy is\n## 0.9985 (95% CI 0.9973, 0.9992)\n\n## So now we work on the actual testing set\npredictionsB2 <- predict(modFitB1, testing, type = \"class\")\n\n## And we do our output files (hoping they are right!)\npml_write_files = function(x){\n  n = length(x)\n  for(i in 1:n){\n    filename = paste0(\"problem_id_\",i,\".txt\")\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\n  }\n}\n\npml_write_files(predictionsB2)\n",
    "created" : 1419196400103.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1660182424",
    "id" : "5571933C",
    "lastKnownWriteTime" : 1419200056,
    "path" : "~/Coursera/R/MachineLearning/MachineLearningCode.R",
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}